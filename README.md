

# ğŸ“Œ Real-Time Caption Generator (CapGenie)

## ğŸ“– Overview

The **Real-Time Caption Generator (CapGenie)** is an innovative system designed to **instantly generate captions from video or audio content with minimal latency**. By leveraging **Whisper ASR** and modern web technologies, it ensures **highly accurate, real-time speech-to-text conversion**.

This project aims to break down accessibility barriers by enabling **inclusive communication** for individuals with hearing impairments, while also serving educators, broadcasters, and content creators.

---

## âœ¨ Key Features

* ğŸ™ï¸ **Real-Time Transcription** â€“ Converts spoken content into text captions instantly.
* ğŸ¨ **Customizable Captions** â€“ Users can change font, color, size, and background for better readability.
* âš¡ **Low Latency Performance** â€“ Optimized pipeline for smooth, real-time transcription.
* ğŸŒ **Multilingual Support (Planned)** â€“ Future expansion for global accessibility.
* ğŸ“± **Responsive React UI** â€“ Intuitive, user-friendly design for seamless cross-platform use.
* ğŸ”’ **Secure & Reliable** â€“ Ensures safe file handling, scalability, and stable performance under load.

---

## ğŸ› ï¸ Tech Stack

**Frontend (UI/UX):**

* React.js
* TailwindCSS (styling & accessibility)

**Backend:**

* Flask + Flask-SocketIO (real-time communication)
* Python

**Speech-to-Text Processing:**

* OpenAI Whisper ASR model
* ffmpeg (audio extraction)

**Testing & Validation:**

* Unit Testing (PyTest)
* Integration Testing
* User Acceptance Testing (UAT)

---

## ğŸ“‚ Project Structure

```plaintext
CapGenie/
â”‚
â”œâ”€â”€ frontend/              # React-based UI
â”‚   â”œâ”€â”€ components/        # Reusable UI elements
â”‚   â”œâ”€â”€ pages/             # Main pages (upload, live stream, etc.)
â”‚   â””â”€â”€ styles/            # Tailwind & custom styles
â”‚
â”œâ”€â”€ backend/               # Flask server
â”‚   â”œâ”€â”€ app.py             # Core backend logic
â”‚   â”œâ”€â”€ socketio_server.py # Real-time server integration
â”‚   â”œâ”€â”€ utils/             # Audio processing, ASR helpers
â”‚   â””â”€â”€ models/            # Whisper ASR setup
â”‚
â”œâ”€â”€ docs/                  # Documentation (Reports, Papers, Diagrams)
â”‚
â”œâ”€â”€ tests/                 # Unit & integration tests
â”‚
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ package.json           # React dependencies
â”œâ”€â”€ README.md              # Project Documentation
â””â”€â”€ LICENSE                # License information
```

---

## âš™ï¸ Installation & Setup

### Prerequisites

* **Python 3.8+**
* **Node.js & npm**
* **ffmpeg** installed locally

### Backend Setup

```bash
# Clone repository
git clone https://github.com/username/CapGenie.git
cd CapGenie/backend

# Create virtual environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

# Install dependencies
pip install -r requirements.txt

# Run backend server
python app.py
```

### Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Start development server
npm start
```

The backend will run on `http://localhost:5000` and the frontend on `http://localhost:3000`.

---

## ğŸ”„ Workflow

1. **Upload / Stream Video** â€“ User uploads video/audio or streams live.
2. **Audio Processing** â€“ Audio is extracted and pre-processed (mono, 16kHz).
3. **ASR Processing** â€“ Whisper model transcribes speech into text in real-time.
4. **Caption Rendering** â€“ Captions displayed instantly via React interface.
5. **Customization** â€“ Users can modify caption appearance to suit accessibility needs.

---

## ğŸ“Š Use Cases

* **Accessibility** â€“ Equal access to media for people with hearing impairments.
* **Education** â€“ Real-time captions for online courses, lectures, and student engagement.
* **Broadcasting** â€“ Captions for live events, webinars, and conferences.
* **Content Creation** â€“ Auto-captioning for YouTube, podcasts, and video tutorials.
* **Multilingual Communication (Future)** â€“ Real-time captions across multiple languages.

---

## ğŸ§ª Testing Strategy

* **Unit Tests** â€“ Validate backend modules (audio extraction, ASR pipeline).
* **Integration Tests** â€“ Ensure seamless interaction between backend and frontend.
* **User Testing** â€“ Collect feedback from educators, hearing-impaired users, and content creators.
* **Performance Benchmarking** â€“ Measure latency, accuracy, and scalability under load.

---

## ğŸš€ Future Enhancements

* ğŸŒ **Multilingual Support** â€“ Real-time translation & captioning in multiple languages.
* ğŸ“± **Mobile App** â€“ Android/iOS application for on-the-go captioning.
* ğŸ¤– **AI-Driven Error Correction** â€“ Automatic correction of transcription errors.
* ğŸ¥ **Streaming Integration** â€“ Native support for Zoom, YouTube Live, Twitch.
* ğŸ“ **Automatic Editing Tools** â€“ Post-transcription caption formatting & corrections.

---

## ğŸ“… Project Timeline (Plan of Work)

| Phase                 | Duration   | Tasks                              |
| --------------------- | ---------- | ---------------------------------- |
| Topic Finalization    | July       | Confirm project scope & objectives |
| Literature Review     | July â€“ Aug | Paper review, data collection      |
| Design & Calculations | Aug        | UI mockups, system design          |
| Development           | Sept â€“ Oct | Backend + Frontend implementation  |
| Testing               | Nov        | Unit, integration, UAT             |
| Documentation         | Dec        | Report writing, project demo       |

---

## ğŸ“š References

* IEEE & ACM research papers on ASR, latency reduction, and captioning.
* Whisper ASR model (OpenAI).
* Jurafsky, D., & Martin, J. H. *Speech and Language Processing* (Pearson, 2021).
* Additional references available in full report documentation.

---

## ğŸ† Expected Outcomes

* **Accurate, low-latency captions** for pre-recorded and live content.
* **Accessibility boost** for individuals with hearing impairments.
* **Improved educational engagement** through captioned lectures.
* **Broadened global reach** with future multilingual capabilities.

---

## ğŸ“œ License

This project is released under the **MIT License**, allowing free use, modification, and distribution with attribution.


---

## ğŸ’¡ Acknowledgments

This project is inspired by the mission of making **digital content accessible to all**, fostering inclusivity, and supporting diverse learners, creators, and communities.

---

âœ¨ **CapGenie â€“ Breaking Barriers, Building Connections.**

